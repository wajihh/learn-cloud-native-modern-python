{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Installing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, you will learn how to install third-party packages using a command called `pip`.\n",
    "\n",
    "Once you have installed a package, you can use functions from the package by importing them using the `import` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages using `pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to install the `bs4` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can safely ignore any warnings you see about upgrading pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bs4 is short for **Beautiful Soup 4**. You can check out the [Beautiful Soup documentation](https://pypi.org/project/beautifulsoup4/) if you want to learn more about the package, but it gives you tools to interpret HTML webpages inside Python programs.\n",
    "\n",
    "Now that you have installed the bs4 package, you can use it in your programs!\n",
    "\n",
    "First, you need to import the `BeautifulSoup` function you'll use from the `bs4` package, as well as some other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests # let's you download webpages into python\n",
    "from helper_functions import * \n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the web\n",
    "\n",
    "In this section, you'll \"scrape\", or download HTML data from a website, in this case from a [Batch newsletter](https://www.deeplearning.ai/the-batch/) published by DeepLearning.AI.\n",
    "\n",
    "You'll use the `requests` Python package to download the data from the webpage and make it available in your program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# The url from one of the Batch's newsletter\n",
    "url = 'https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/'\n",
    "\n",
    "# Getting the content from the webpage's contents\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the response from the requests\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `<Response [200]>` you see is an indication from the requests library that your HTTP request was successful. You can ask the chatbot for details about other codes you might see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have downloaded the content from the website, you can display it in the notebook using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "HTML(f'<iframe src={url} width=\"60%\" height=\"400\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll use Beautiful Soup to extract all the text paragraphs from the HTML structure that you retrieved, and save it as a single string. Here is the code to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# Using beautifulsoup to extract the text\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# Find all the text in paragraph elements on the webpage\n",
    "all_text = soup.find_all('p')\n",
    "\n",
    "# Create an empty string to store the extracted text\n",
    "combined_text = \"\"\n",
    "\n",
    "# Iterate over 'all_text' and add to the combined_text string\n",
    "for text in all_text:\n",
    "    combined_text = combined_text + \"\\n\" + text.get_text()\n",
    "\n",
    "# Print the final combined text\n",
    "print(combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details about how this code works, you can ask the chatbot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "<br><br>\n",
    "What is the following code doing?\n",
    "<br><br>\n",
    "soup = BeautifulSoup(response.text, 'html.parser')<br>\n",
    "all_text = soup.find_all('p')\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information from scraped website data using LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass the text you just extracted from the Batch newsletter website to an LLM and ask it to extract the most relevant information for you.\n",
    "\n",
    "Start by writing the prompt and passing in the text you extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Extract the key bullet points from the following text.\n",
    "\n",
    "Text:\n",
    "{combined_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass the prompt to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more example of installing packages\n",
    "\n",
    "Throughout the courses so far, you've imported helper functions from a file called `helper_functions.py` using commands like `from helper_functions import get_llm_response`.\n",
    "\n",
    "The DeepLearning.AI team has created a third-party package called `aisetup` that you can use to access the helper functions from the course in your own code outside of this learning platform.\n",
    "\n",
    "To install it, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!pip install aisetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the package is installed, you can import helper functions from it using the `import` command. For example, if you want to import `get_llm_response`, you now run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from aisetup import get_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "response = get_llm_response(\"Why is the programming language called Python?\")\n",
    "\n",
    "# Print LLMs response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra practice\n",
    "\n",
    "Try the following exercises to test what you have learned. If you get stuck, as the chatbot for help!\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Modify the following code to answer the following question:\n",
    "- Who built the new short course mentioned in the letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Modify the prompt\n",
    "prompt = f\"\"\"YOUR PROMPT HERE\n",
    "\n",
    "Text:\n",
    "{combined_text}\n",
    "\"\"\"\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the `celsius_to_fahrenheit` function in the `aisetup` package to calculate the Fahrenheit equivalent of 0 degrees Celsius.\n",
    "\n",
    "You'll need to complete the import statement and the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "\n",
    "# Complete the import statement\n",
    "from\n",
    "\n",
    "# Complete the calculation\n",
    "zero_celsius_in_fahrenheit =\n",
    "print (zero_celsius_in_fahrenheit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge exercise!\n",
    "\n",
    "Write code that uses the `bs4` package to create a string that contains the **title element from the Batch newsletter**. This is the text that starts \"The World Needs More Intelligence\".\n",
    "\n",
    "**Hint 1:** Titles on webpages are often header elements, with tags like `<h1>` or `<h2>`.\n",
    "**Hint 2:** Ask the chatbot for help, using the code you have already written as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "title =\n",
    "\n",
    "print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
